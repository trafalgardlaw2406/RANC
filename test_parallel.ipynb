{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_parallel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpliXgb42eNNXhBqhPYNsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trafalgardlaw2406/RANC/blob/main/test_parallel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd18XgtbTYcl",
        "outputId": "32a7948d-d766-47f6-d46f-d77252ebf222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import operator\n",
        "import functools\n",
        "import math\n",
        "import os\n",
        "\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Activation, Input, Lambda, concatenate,Average\n",
        "from tensorflow.keras.datasets import mnist,fashion_mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import constraints\n",
        "import sys\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SRuTsb8TsV-",
        "outputId": "910adeb3-92a2-475a-80fe-0130a2d75902"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tea(Layer):\n",
        "    def __init__(self,\n",
        "                 units,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initializes a new TeaLayer.\n",
        "\n",
        "        Arguments:\n",
        "            units -- The number of neurons to use for this layer.\"\"\"\n",
        "        self.units = units\n",
        "        # Needs to be set to `True` to use the `K.in_train_phase` function.\n",
        "        self.uses_learning_phase = True\n",
        "        super(Tea, self).__init__(**kwargs)\n",
        "\n",
        "def tea_weight_initializer(shape, dtype=np.float32):\n",
        "    \"\"\"Returns a tensor of alternating 1s and -1s, which is (kind of like)\n",
        "    how IBM initializes their weight matrix in their TeaLearning\n",
        "    literature.\n",
        "\n",
        "    Arguments:\n",
        "        shape -- The shape of the weights to intialize.\n",
        "\n",
        "    Keyword Arguments:\n",
        "        dtype -- The data type to use to initialize the weights.\n",
        "                 (default: {np.float32})\"\"\"\n",
        "    num_axons = shape[0]\n",
        "    num_neurons = shape[1]\n",
        "    ret_array = np.zeros((int(num_axons), int(num_neurons)), dtype=np.float32)\n",
        "    for axon_num, axon in enumerate(ret_array):\n",
        "        if axon_num % 2 == 0:\n",
        "            for i in range(len(axon)):\n",
        "                ret_array[axon_num][i] = 1\n",
        "        else:\n",
        "            for i in range(len(axon)):\n",
        "                ret_array[axon_num][i] = -1\n",
        "    return tf.convert_to_tensor(ret_array)\n",
        "\n",
        "def build(self, input_shape):\n",
        "    assert len(input_shape) >= 2\n",
        "    shape = (input_shape[-1], self.units)\n",
        "    self.static_weights = self.add_weight(\n",
        "        name='weights',\n",
        "        shape=shape,\n",
        "        initializer=tea_weight_initializer,\n",
        "        trainable=False)\n",
        "    # Intialize connections around 0.5 because they represent probabilities.\n",
        "    self.connections = self.add_weight(\n",
        "        name='connections',\n",
        "        initializer=initializers.TruncatedNormal(mean=0.5),\n",
        "        shape=shape)\n",
        "    self.biases = self.add_weight(\n",
        "        name='biases',\n",
        "        initializer='zeros',\n",
        "        shape=(self.units,))\n",
        "    super(Tea, self).build(input_shape)\n",
        "\n",
        "# Bind the method to our class\n",
        "Tea.build = build\n",
        "\n",
        "def call(self, x):\n",
        "    with tf.get_default_graph().gradient_override_map(\n",
        "        {\"Round\":\"CustomRound\"}):\n",
        "        # Constrain input\n",
        "        x = tf.round(x)\n",
        "        # Constrain connections\n",
        "        connections = self.connections\n",
        "        connections = tf.round(connections)\n",
        "        connections = K.clip(connections, 0, 1)\n",
        "        # Multiply connections with weights\n",
        "        weighted_connections = connections * self.static_weights\n",
        "        # Dot input with weighted connections\n",
        "        output = K.dot(x, weighted_connections)\n",
        "        # Constrain biases\n",
        "        biases = tf.round(self.biases)\n",
        "        output = K.bias_add(\n",
        "            output,\n",
        "            biases,\n",
        "            data_format='channels_last'\n",
        "        )\n",
        "        # Apply activation / spike\n",
        "        output = K.in_train_phase(\n",
        "            K.sigmoid(output),\n",
        "            tf.cast(tf.greater_equal(output, 0.0), tf.float32)\n",
        "        )\n",
        "    return output\n",
        "    \n",
        "# Bind the method to our class\n",
        "Tea.call = call\n",
        "\n",
        "def compute_output_shape(self, input_shape):\n",
        "    assert input_shape and len(input_shape) >= 2\n",
        "    assert input_shape[-1]\n",
        "    output_shape = list(input_shape)\n",
        "    output_shape[-1] = self.units\n",
        "    return tuple(output_shape)\n",
        "    \n",
        "# Bind the method to our class\n",
        "Tea.compute_output_shape = compute_output_shape\n",
        "\n",
        "\n",
        "class AdditivePooling(Layer):\n",
        "    \"\"\"A helper layer designed to format data for output during TeaLearning.\n",
        "    If the data input to the layer has multiple spikes per classification, the\n",
        "    spikes for each tick are summed up. Then, all neurons that correspond to a\n",
        "    certain class are summed up so that the output is the number of spikes for\n",
        "    each class. Neurons are assumed to be arranged such that each\n",
        "    `num_classes` neurons represent a guess for each of the classes. For\n",
        "    example, if the guesses correspond to number from 0 to 9, the nuerons are\n",
        "    arranged as such:\n",
        "\n",
        "        neuron_num: 0  1  2  3  4  5  6  7  8  9  10 11 12  ...\n",
        "        guess:      0  1  2  3  4  5  6  7  8  9  0  1  2   ...\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initializes a new `AdditivePooling` layer.\n",
        "\n",
        "        Arguments:\n",
        "            num_classes -- The number of classes to output.\n",
        "        \"\"\"\n",
        "        self.num_classes = num_classes\n",
        "        self.num_inputs = None\n",
        "        super(AdditivePooling, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        # The number of neurons must be collapsable into the number of classes\n",
        "        assert input_shape[-1] % self.num_classes == 0\n",
        "        self.num_inputs = input_shape[-1]\n",
        "\n",
        "    def call(self, x):\n",
        "        # Sum up ticks if there are ticks\n",
        "        if len(x.shape) >= 3:\n",
        "            output = K.sum(x, axis=1)\n",
        "        else:\n",
        "            output = x\n",
        "        # Reshape output\n",
        "        output = tf.reshape(\n",
        "            output,\n",
        "            [-1, int(self.num_inputs // self.num_classes), self.num_classes]\n",
        "        )\n",
        "        # Sum up neurons\n",
        "        output = tf.reduce_sum(output, 1)\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        # Last dimension will be number of classes\n",
        "        output_shape[-1] = self.num_classes\n",
        "        # Ticks were summed, so delete tick dimension if exists\n",
        "        if len(output_shape) >= 3:\n",
        "            del output_shape[1]\n",
        "        return tuple(output_shape)"
      ],
      "metadata": {
        "id": "HJN-VUN6Tx7O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Load\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch (modeling)\n",
        "# import torch\n",
        "# from torch import nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# from torchvision import transforms\n",
        "# import torchvision.transforms.functional as TF\n",
        "# from torch.utils.data import Dataset\n",
        "# from torch.utils.data import random_split\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# # Visualization\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "from scipy import ndimage\n",
        "\n",
        "# These functions are introduced along the Part 1 notebook.\n",
        "\n",
        "# Position vectors. We load the data with respect to the file name, which is\n",
        "# a number corresponding to a specific in-bed position. We take advantage of this\n",
        "# and use the number to get the position with help of the following vectors.\n",
        "\n",
        "positions_i = [\"justAPlaceholder\", \"supine_1\", \"right_0\",\n",
        "               \"left_0\", \"right_30\", \"right_60\",\n",
        "               \"left_30\", \"left_60\", \"supine_2\",\n",
        "               \"supine_3\", \"supine_4\", \"supine_5\",\n",
        "               \"supine_6\", \"right_fetus\", \"left_fetus\",\n",
        "               \"supine_30\", \"supine_45\", \"supine_60\"]\n",
        "\n",
        "positions_i_short = [\"justAPlaceholder\", \"supine\", \"right\",\n",
        "               \"left\", \"right\", \"right\",\n",
        "               \"left\", \"left\", \"supine\",\n",
        "               \"supine\", \"supine\", \"supine\",\n",
        "               \"supine\", \"right\", \"left\",\n",
        "               \"supine\", \"supine\", \"supine\"]\n",
        "\n",
        "positions_ii = {\n",
        "    \"B\":\"supine\", \"1\":\"supine\", \"C\":\"right\",\n",
        "    \"D\":\"left\", \"E1\":\"right\", \"E2\":\"right\",\n",
        "    \"E3\":\"left\", \"E4\":\"left\", \"E5\":\"right\",\n",
        "    \"E6\":\"left\", \"F\":\"supine\", \"G1\":\"supine\",\n",
        "    \"G2\":\"right\", \"G3\":\"left\"\n",
        "}\n",
        "\n",
        "class_positions = ['supine', 'left', 'right', 'left_fetus', 'right_fetus']\n",
        "\n",
        "# We also want the classes to be encoded as numbers so we can work easier when\n",
        "# modeling. This function achieves so. Since left_fetus and right_fetus are not\n",
        "# considered as classes in the evaluation of the original paper and since they\n",
        "# are not considered in the \"Experiment I\", we encode them also as left and right\n",
        "# positions.\n",
        "\n",
        "def token_position_short(x):\n",
        "  return {\n",
        "      'supine': 0,\n",
        "      'left': 1,\n",
        "      'right': 2,\n",
        "      'left_fetus': 1,\n",
        "      'right_fetus': 2\n",
        "  }[x]\n",
        "\n",
        "def token_position(x):\n",
        "  return {\n",
        "      \"supine_1\":0, \n",
        "      \"right_0\":1,\n",
        "      \"left_0\":2, \n",
        "      \"right_30\":3, \n",
        "      \"right_60\":4,\n",
        "      \"left_30\":5, \n",
        "      \"left_60\":6, \n",
        "      \"supine_2\":7,\n",
        "      \"supine_3\":8, \n",
        "      \"supine_4\":9, \n",
        "      \"supine_5\":10,\n",
        "      \"supine_6\":11, \n",
        "      \"right_fetus\":12, \n",
        "      \"left_fetus\":13,\n",
        "      \"supine_30\":14, \n",
        "      \"supine_45\":15, \n",
        "      \"supine_60\":16\n",
        "  }[x]\n",
        "\n",
        "def token_position_new(x):\n",
        "  return {\n",
        "      \"supine_1\":0, \n",
        "      \"supine_2\":1,\n",
        "      \"supine_3\":2, \n",
        "      \"supine_4\":3, \n",
        "      \"supine_5\":4,\n",
        "      \"supine_6\":5, \n",
        "      \"supine_30\":6, \n",
        "      \"supine_45\":7, \n",
        "      \"supine_60\":8, \n",
        "      \"left_0\":9, \n",
        "      \"left_30\":10, \n",
        "      \"left_60\":11,\n",
        "      \"left_fetus\":12, \n",
        "      \"right_0\":13,\n",
        "      \"right_30\":14, \n",
        "      \"right_60\":15,\n",
        "      \"right_fetus\":16, \n",
        "  }[x]\n",
        "list_supine = [\"1.txt\",\"8.txt\",\"9.txt\",\"10.txt\",\"11.txt\",\"12.txt\",\"15.txt\",\"16.txt\",\"17.txt\"]\n",
        "\n",
        "list_supine_norm_1 = [\"1.txt\",\"8.txt\",\"9.txt\"]\n",
        "\n",
        "list_supine_norm_2 = [\"10.txt\",\"11.txt\",\"12.txt\"]\n",
        "\n",
        "list_supine_incl = [\"15.txt\",\"16.txt\",\"17.txt\"]\n",
        "\n",
        "list_left = [\"3.txt\",\"6.txt\",\"7.txt\",\"14.txt\"]\n",
        "\n",
        "list_right = [\"2.txt\",\"4.txt\",\"5.txt\",\"13.txt\"]\n",
        "\n",
        "def token_position_supine(x):\n",
        "  return {\n",
        "      \"supine_1\":0, \n",
        "      \"supine_2\":1,\n",
        "      \"supine_3\":2, \n",
        "      \"supine_4\":3, \n",
        "      \"supine_5\":4,\n",
        "      \"supine_6\":5, \n",
        "      \"supine_30\":6, \n",
        "      \"supine_45\":7, \n",
        "      \"supine_60\":8\n",
        "    }[x]\n",
        "\n",
        "def token_position_supine_norm_1(x):\n",
        "  return {\n",
        "      \"supine_1\":0, \n",
        "      \"supine_2\":1,\n",
        "      \"supine_3\":2, \n",
        "    }[x]\n",
        "\n",
        "def token_position_supine_norm_2(x):\n",
        "  return {\n",
        "      \"supine_4\":0, \n",
        "      \"supine_5\":1,\n",
        "      \"supine_6\":2, \n",
        "    }[x]\n",
        "\n",
        "def token_position_supine_incl(x):\n",
        "  return {\n",
        "      \"supine_30\":0, \n",
        "      \"supine_45\":1, \n",
        "      \"supine_60\":2\n",
        "    }[x]\n",
        "\n",
        "def token_position_left(x):\n",
        "  return {\n",
        "      \"left_0\":0, \n",
        "      \"left_30\":1, \n",
        "      \"left_60\":2,\n",
        "      \"left_fetus\":3,\n",
        "  }[x]\n",
        "\n",
        "def token_position_right(x):\n",
        "  return {\n",
        "      \"right_0\":0,\n",
        "      \"right_30\":1, \n",
        "      \"right_60\":2,\n",
        "      \"right_fetus\":3, \n",
        "  }[x]\n",
        "\n",
        "\n",
        "def load_exp_i(path,preprocess=True):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      max_val = []\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            lines = f.read().splitlines()[2:]\n",
        "            for i in range(3, len(lines) - 3):\n",
        "                              \n",
        "              raw_data = np.fromstring(lines[i], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "              if preprocess is True:\n",
        "                past_image = np.fromstring(lines[i-1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image = np.fromstring(lines[i+1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                \n",
        "                # Spatio-temporal median filter 3x3x3\n",
        "                raw_data = ndimage.median_filter(raw_data, 3)\n",
        "                past_image = ndimage.median_filter(past_image, 3)\n",
        "                future_image = ndimage.median_filter(future_image, 3)\n",
        "                raw_data = np.concatenate((raw_data[np.newaxis, :, :], past_image[np.newaxis, :, :], future_image[np.newaxis, :, :]), axis=0)\n",
        "                raw_data = np.median(raw_data, axis=0)\n",
        "            \n",
        "            # with open(file_path, 'r') as f:\n",
        "            #   # Start from second recording, as the first two are corrupted\n",
        "            #   lines = f.read().splitlines()[2:]\n",
        "            #   for line in f.read().splitlines()[2:]:\n",
        "            #     # print(line)\n",
        "            #     raw_data = np.fromstring(line, dtype=float, sep='\\t')\n",
        "                # Change the range from [0-1000] to [0-255].\n",
        "                  # max_val.append(np.amax(raw_data))\n",
        "              file_data = np.round(raw_data*255/1000).astype(np.uint8)\n",
        "              # file_data = np.round(raw_data).astype(np.uint8)\n",
        "              \n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "              # print(positions_i[int(file[:-4])])\n",
        "              file_label = token_position(positions_i[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "      \n",
        "      # max_over_all = max(max_val)\n",
        "      # print(max_over_all)\n",
        "\n",
        "      # data = np.round(data * 255/1000).astype(np.uint8)\n",
        "      dataset[subject] = (data, labels)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_short(path,preprocess=True):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      max_val = []\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            lines = f.read().splitlines()[2:]\n",
        "            for i in range(3, len(lines) - 3):\n",
        "                              \n",
        "              raw_data = np.fromstring(lines[i], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "              if preprocess is True:\n",
        "                past_image = np.fromstring(lines[i-1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image = np.fromstring(lines[i+1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                \n",
        "                # Spatio-temporal median filter 3x3x3\n",
        "                raw_data = ndimage.median_filter(raw_data, 3)\n",
        "                past_image = ndimage.median_filter(past_image, 3)\n",
        "                future_image = ndimage.median_filter(future_image, 3)\n",
        "                raw_data = np.concatenate((raw_data[np.newaxis, :, :], past_image[np.newaxis, :, :], future_image[np.newaxis, :, :]), axis=0)\n",
        "                raw_data = np.median(raw_data, axis=0)\n",
        "              file_data = np.round(raw_data*255/1000).astype(np.uint8)\n",
        "              # file_data = np.round(raw_data).astype(np.uint8)\n",
        "              \n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "              # print(positions_i[int(file[:-4])])\n",
        "              file_label = token_position_short(positions_i_short[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "      dataset[subject] = (data, labels)\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_supine(path,preprocess=True):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        files = list_supine\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            # Start from second recording, as the first two are corrupted\n",
        "            lines = f.read().splitlines()[2:]\n",
        "            for i in range(5, len(lines) - 5):\n",
        "                            \n",
        "              raw_data = np.fromstring(lines[i], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "              if preprocess is True:\n",
        "                past_image_1 = np.fromstring(lines[i-1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image_1 = np.fromstring(lines[i+1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                past_image_2 = np.fromstring(lines[i-2], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image_2 = np.fromstring(lines[i+2], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "                # Spatio-temporal median filter 5x5x5\n",
        "              \n",
        "                raw_data = ndimage.median_filter(raw_data, 3)\n",
        "                \n",
        "                past_image_1 = ndimage.median_filter(past_image_1, 3)\n",
        "                future_image_1 = ndimage.median_filter(future_image_1, 3)\n",
        "                past_image_2 = ndimage.median_filter(past_image_2, 3)\n",
        "                future_image_2 = ndimage.median_filter(future_image_2, 3)\n",
        "\n",
        "                raw_data = np.concatenate((past_image_2[np.newaxis, :, :],past_image_1[np.newaxis, :, :] ,raw_data[np.newaxis, :, :], \\\n",
        "                future_image_1[np.newaxis, :, :],future_image_2[np.newaxis, :, :]), axis=0)\n",
        "                raw_data = np.median(raw_data, axis=0)\n",
        "              \n",
        "              # a=np.amax(raw_data)\n",
        "\n",
        "              file_data = np.round(raw_data*255/1000).astype(np.uint8)\n",
        "              \n",
        "              # file_data = np.round(raw_data).astype(np.uint8)\n",
        "              \n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "\n",
        "              file_label = token_position_supine(positions_i[int(file[:-4])])\n",
        "              \n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "      dataset[subject] = (data, labels)\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_supine_norm_1(path):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        files = list_supine_norm_1\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            # Start from second recording, as the first two are corrupted\n",
        "            for line in f.read().splitlines()[2:]:\n",
        "              # print(line)\n",
        "              raw_data = np.fromstring(line, dtype=float, sep='\\t')\n",
        "              # Change the range from [0-1000] to [0-255].\n",
        "              max_val = np.amax(raw_data)\n",
        "              file_data = np.round(raw_data*255/max_val).astype(np.uint8)\n",
        "              \n",
        "              # file_data = np.round(raw_data).astype(float)\n",
        "              \n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "\n",
        "              file_label = token_position_supine_norm_1(positions_i[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "      dataset[subject] = (data, labels)\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_supine_norm_2(path):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        files = list_supine_norm_2\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            # Start from second recording, as the first two are corrupted\n",
        "            for line in f.read().splitlines()[2:]:\n",
        "              # print(line)\n",
        "              raw_data = np.fromstring(line, dtype=float, sep='\\t')\n",
        "              # Change the range from [0-1000] to [0-255].\n",
        "              max_val = np.amax(raw_data)\n",
        "              file_data = np.round(raw_data*255/max_val).astype(np.uint8)\n",
        "              \n",
        "              # file_data = np.round(raw_data).astype(float)\n",
        "              \n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "\n",
        "              file_label = token_position_supine_norm_2(positions_i[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "      dataset[subject] = (data, labels)\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_supine_incl(path,preprocess=True):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        files = list_supine_incl\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            # Start from second recording, as the first two are corrupted\n",
        "            # with open(file_path, 'r') as f:\n",
        "            lines = f.read().splitlines()[2:]\n",
        "            for i in range(3, len(lines) - 3):\n",
        "\n",
        "              raw_data = np.fromstring(lines[i], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "              if preprocess is True:\n",
        "                past_image = np.fromstring(lines[i-1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image = np.fromstring(lines[i+1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                \n",
        "                # Spatio-temporal median filter 3x3x3\n",
        "                raw_data = ndimage.median_filter(raw_data, 3)\n",
        "                past_image = ndimage.median_filter(past_image, 3)\n",
        "                future_image = ndimage.median_filter(future_image, 3)\n",
        "                raw_data = np.concatenate((raw_data[np.newaxis, :, :], past_image[np.newaxis, :, :], future_image[np.newaxis, :, :]), axis=0)\n",
        "                raw_data = np.median(raw_data, axis=0)\n",
        "\n",
        "              # Change the range from [0-1000] to [0-255].\n",
        "              # max_vol = np.amax(raw_data)\n",
        "              file_data = np.round(raw_data ).astype(np.uint8)\n",
        "\n",
        "              # file_data = np.round(raw_data).astype(np.uint8)\n",
        "              file_data = file_data.reshape(1, 64, 32)\n",
        "\n",
        "              file_label = token_position_supine_incl(positions_i[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "      dataset[subject] = (data, labels)\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_left(path,preprocess=True):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        files = list_left\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            # Start from second recording, as the first two are corrupted\n",
        "            lines = f.read().splitlines()[2:]\n",
        "            for i in range(5, len(lines) - 5):\n",
        "                            \n",
        "              raw_data = np.fromstring(lines[i], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "              if preprocess is True:\n",
        "                past_image_1 = np.fromstring(lines[i-1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image_1 = np.fromstring(lines[i+1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                past_image_2 = np.fromstring(lines[i-2], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image_2 = np.fromstring(lines[i+2], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "                # Spatio-temporal median filter 5x5x5\n",
        "              \n",
        "                raw_data = ndimage.median_filter(raw_data, 3)\n",
        "                \n",
        "                past_image_1 = ndimage.median_filter(past_image_1, 3)\n",
        "                future_image_1 = ndimage.median_filter(future_image_1, 3)\n",
        "                past_image_2 = ndimage.median_filter(past_image_2, 3)\n",
        "                future_image_2 = ndimage.median_filter(future_image_2, 3)\n",
        "\n",
        "                raw_data = np.concatenate((past_image_2[np.newaxis, :, :],past_image_1[np.newaxis, :, :] ,raw_data[np.newaxis, :, :], \\\n",
        "                future_image_1[np.newaxis, :, :],future_image_2[np.newaxis, :, :]), axis=0)\n",
        "                raw_data = np.median(raw_data, axis=0)\n",
        "          # with open(file_path, 'r') as f:\n",
        "          #   # Start from second recording, as the first two are corrupted\n",
        "          #   for line in f.read().splitlines()[2:]:\n",
        "          #     # print(line)\n",
        "          #     raw_data = np.fromstring(line, dtype=float, sep='\\t')\n",
        "          #     # Change the range from [0-1000] to [0-255].\n",
        "\n",
        "              file_data = np.round(raw_data*255/1000).astype(np.uint8)\n",
        "              \n",
        "\n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "\n",
        "              file_label = token_position_left(positions_i[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "      dataset[subject] = (data, labels)\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_right(path,preprocess=True):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        files = list_right\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            # Start from second recording, as the first two are corrupted\n",
        "            lines = f.read().splitlines()[2:]\n",
        "            for i in range(5, len(lines) - 5):\n",
        "                            \n",
        "              raw_data = np.fromstring(lines[i], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "              if preprocess is True:\n",
        "                past_image_1 = np.fromstring(lines[i-1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image_1 = np.fromstring(lines[i+1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                past_image_2 = np.fromstring(lines[i-2], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image_2 = np.fromstring(lines[i+2], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "                # Spatio-temporal median filter 5x5x5\n",
        "              \n",
        "                raw_data = ndimage.median_filter(raw_data, 3)\n",
        "                \n",
        "                past_image_1 = ndimage.median_filter(past_image_1, 3)\n",
        "                future_image_1 = ndimage.median_filter(future_image_1, 3)\n",
        "                past_image_2 = ndimage.median_filter(past_image_2, 3)\n",
        "                future_image_2 = ndimage.median_filter(future_image_2, 3)\n",
        "\n",
        "                raw_data = np.concatenate((past_image_2[np.newaxis, :, :],past_image_1[np.newaxis, :, :] ,raw_data[np.newaxis, :, :], \\\n",
        "                future_image_1[np.newaxis, :, :],future_image_2[np.newaxis, :, :]), axis=0)\n",
        "                raw_data = np.median(raw_data, axis=0)\n",
        "              # Change the range from [0-1000] to [0-255].\n",
        "              file_data = np.round(raw_data*255/1000).astype(np.uint8)\n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "\n",
        "              file_label = token_position_right(positions_i[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "      dataset[subject] = (data, labels)\n",
        "  return dataset\n",
        "\n",
        "def load_exp_i_new(path,preprocess=True):\n",
        "  \"\"\"\n",
        "  Creates a numpy array for the data and labels.\n",
        "  params:\n",
        "  ------\n",
        "  path    -- Data path.\n",
        "  returns:\n",
        "  -------\n",
        "  A numpy array (data, labels).\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = {}\n",
        "\n",
        "  for _, dirs, _ in os.walk(path):\n",
        "    for directory in dirs:\n",
        "      # each directory is a subject\n",
        "      subject = directory\n",
        "      data = None\n",
        "      labels = None\n",
        "      max_val = []\n",
        "      for _, _, files in os.walk(os.path.join(path, directory)):\n",
        "        # print(files)\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path = os.path.join(path, directory, file)\n",
        "          with open(file_path, 'r') as f:\n",
        "            lines = f.read().splitlines()[2:]\n",
        "            for i in range(3, len(lines) - 3):\n",
        "                              \n",
        "              raw_data = np.fromstring(lines[i], dtype=float, sep='\\t').reshape(64, 32)\n",
        "              \n",
        "              if preprocess is True:\n",
        "                past_image = np.fromstring(lines[i-1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                future_image = np.fromstring(lines[i+1], dtype=float, sep='\\t').reshape(64, 32)\n",
        "                \n",
        "                # Spatio-temporal median filter 3x3x3\n",
        "                raw_data = ndimage.median_filter(raw_data, 3)\n",
        "                past_image = ndimage.median_filter(past_image, 3)\n",
        "                future_image = ndimage.median_filter(future_image, 3)\n",
        "                raw_data = np.concatenate((raw_data[np.newaxis, :, :], past_image[np.newaxis, :, :], future_image[np.newaxis, :, :]), axis=0)\n",
        "                raw_data = np.median(raw_data, axis=0)\n",
        "            \n",
        "            # with open(file_path, 'r') as f:\n",
        "            #   # Start from second recording, as the first two are corrupted\n",
        "            #   lines = f.read().splitlines()[2:]\n",
        "            #   for line in f.read().splitlines()[2:]:\n",
        "            #     # print(line)\n",
        "            #     raw_data = np.fromstring(line, dtype=float, sep='\\t')\n",
        "                # Change the range from [0-1000] to [0-255].\n",
        "                  # max_val.append(np.amax(raw_data))\n",
        "              file_data = np.round(raw_data*255/1000).astype(np.uint8)\n",
        "              # file_data = np.round(raw_data).astype(np.uint8)\n",
        "              \n",
        "              file_data = file_data.reshape((1,64,32))\n",
        "              # print(positions_i[int(file[:-4])])\n",
        "              file_label = token_position_new(positions_i[int(file[:-4])])\n",
        "              # print(\"directory: \",directory,\"file_name: \" ,file,\"file_label: \",file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "      \n",
        "      # max_over_all = max(max_val)\n",
        "      # print(max_over_all)\n",
        "\n",
        "      # data = np.round(data * 255/1000).astype(np.uint8)\n",
        "      dataset[subject] = (data, labels)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "def load_exp_ii(path):\n",
        "\n",
        "  exp_ii_data_air = {}\n",
        "  exp_ii_data_spo = {}\n",
        "\n",
        "  # each directory is a subject\n",
        "  for _, subject_dirs, _ in os.walk(path):\n",
        "    for subject in subject_dirs:\n",
        "      data = None\n",
        "      labels = None\n",
        "\n",
        "      # each directory is a matresss\n",
        "      for _, mat_dirs, _ in os.walk(os.path.join(path, subject)):\n",
        "        for mat in mat_dirs:\n",
        "          for _, _, files in os.walk(os.path.join(path, subject, mat)):\n",
        "            for file in files:\n",
        "              file_path = os.path.join(path, subject, mat, file)\n",
        "              raw_data = np.loadtxt(file_path)\n",
        "              # Change the range from [0-500] to [0-255].\n",
        "              file_data = np.round(raw_data*255/500).astype(np.uint8)\n",
        "              \n",
        "              file_data = resize_and_rotate(file_data)\n",
        "              \n",
        "              file_data = file_data.view(1, 64, 32)\n",
        "\n",
        "              if file[-6] == \"E\" or file[-6] == \"G\":\n",
        "                file_label = positions_ii[file[-6:-4]]\n",
        "              else:\n",
        "                file_label = positions_ii[file[-6]]\n",
        "\n",
        "              file_label = token_position(file_label)\n",
        "              file_label = np.array([file_label])\n",
        "\n",
        "              if data is None:\n",
        "                data = file_data\n",
        "              else:\n",
        "                data = np.concatenate((data, file_data), axis=0)\n",
        "\n",
        "              if labels is None:\n",
        "                labels = file_label\n",
        "              else:\n",
        "                labels = np.concatenate((labels, file_label), axis=0)\n",
        "\n",
        "          if mat == \"Air_Mat\":\n",
        "            exp_ii_data_air[subject] = (data, labels)\n",
        "          else:\n",
        "            exp_ii_data_spo[subject] = (data, labels)\n",
        "\n",
        "          data = None\n",
        "          labels = None\n",
        "\n",
        "    return exp_ii_data_air, exp_ii_data_spo\n",
        "\n",
        "import cv2 \n",
        "\n",
        "class Mat_Dataset():\n",
        "  def __init__(self,datasets, mats, Subject_IDs):\n",
        "\n",
        "    self.samples = []\n",
        "    self.labels = []\n",
        "\n",
        "    for mat in mats:\n",
        "      data = datasets[mat]\n",
        "      self.samples.append(np.vstack([data.get(key)[0] for key in Subject_IDs]))\n",
        "      self.labels.append(np.hstack([data.get(key)[1] for key in Subject_IDs]))\n",
        "\n",
        "    self.samples = np.vstack(self.samples)\n",
        "    self.labels = np.hstack(self.labels)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.samples.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.samples[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "pOAr_pi3T2Fl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.RegisterGradient(\"CustomRound\")\n",
        "def _const_round_grad(unused_op, grad):\n",
        "    return grad"
      ],
      "metadata": {
        "id": "w-t9X5O2T4zG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "QBpoRRGtT95G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_i_data = load_exp_i_supine(\"/content/drive/MyDrive/RANC/dataset/experiment-i\")\n",
        "\n",
        "datasets = {\"Base\":exp_i_data}\n",
        "\n",
        "subjects = [\"S1\",\"S2\",\"S3\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\",\"S11\",\"S12\",\"S13\"]\n",
        "\n",
        "\n",
        "sub=\"S2\"\n",
        "\n",
        "subjects.remove(sub)\n",
        "random.seed(1)\n",
        "random.shuffle(subjects)\n",
        "\n",
        "\n",
        "train_data = Mat_Dataset(datasets,[\"Base\"],subjects)\n",
        " \n",
        "test_data = Mat_Dataset(datasets,[\"Base\"],[sub])"
      ],
      "metadata": {
        "id": "KGqwuhrnUBj1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# acc_per_so = []\n",
        "# loss_per_so = []\n",
        "# ls_train_full = subjects.copy()\n",
        "\n",
        "# for sub in ls_train_full:\n",
        "#   subjects.remove(sub)\n",
        "#   train_data = Mat_Dataset(datasets,[\"Base\"],subjects)\n",
        "#   test_data = Mat_Dataset(datasets,[\"Base\"],[sub])\n",
        "\n",
        "y_train = to_categorical(train_data.labels, 9)\n",
        "y_test = to_categorical(test_data.labels, 9)\n",
        "\n",
        "x_train = []\n",
        "\n",
        "for i in range(len(train_data.samples)):\n",
        "    \n",
        "    train_data.samples[i] = cv2.equalizeHist(train_data.samples[i])\n",
        "\n",
        "    heat = cv2.applyColorMap(train_data.samples[i], cv2.COLORMAP_JET)\n",
        "    mask = np.ones_like(heat)\n",
        "    bin1 = np.array(heat>=mask*63).astype(np.uint8)\n",
        "    bin2 = np.array(heat>=mask*127).astype(np.uint8)\n",
        "    bin3 = np.array(heat>=mask*190).astype(np.uint8)\n",
        "    bin_out = np.concatenate((bin1,bin2,bin3),axis=2)\n",
        "\n",
        "    x_train.append(bin_out)\n",
        "\n",
        "x_test = []\n",
        "\n",
        "for i in range(len(test_data.samples)):\n",
        "\n",
        "    test_data.samples[i] = cv2.equalizeHist(test_data.samples[i])\n",
        "    \n",
        "    heat = cv2.applyColorMap(test_data.samples[i], cv2.COLORMAP_JET)\n",
        "    mask = np.ones_like(heat)\n",
        "    bin1 = np.array(heat>=mask*63).astype(np.uint8)\n",
        "    bin2 = np.array(heat>=mask*127).astype(np.uint8)\n",
        "    bin3 = np.array(heat>=mask*190).astype(np.uint8)\n",
        "    bin_out = np.concatenate((bin1,bin2,bin3),axis=2)\n",
        "\n",
        "    x_test.append(bin_out)\n",
        "x_train = np.array(x_train).astype(np.uint8)\n",
        "x_test = np.array(x_test).astype(np.uint8)\n",
        "inputs = Input(shape=(64, 32,9))\n",
        "\n",
        "  # permute = Permute((2,1,3))(inputs)\n",
        "flattened = Flatten()(inputs)\n",
        "\n",
        "flattened_inputs_1 = Lambda(lambda x : x[:,      :2048*3 ])(flattened)\n",
        "flattened_inputs_2 = Lambda(lambda x : x[:,2048*3:2048*6])(flattened)\n",
        "flattened_inputs_3 = Lambda(lambda x : x[:,2048*6: ])(flattened)\n",
        "\n",
        "R_1 = Lambda(lambda x : x[:,     :2048 ])(flattened_inputs_1)\n",
        "G_1 = Lambda(lambda x : x[:, 2048:4096 ])(flattened_inputs_1)\n",
        "B_1 = Lambda(lambda x : x[:, 4096:     ])(flattened_inputs_1)\n",
        "R_2 = Lambda(lambda x : x[:,     :2048 ])(flattened_inputs_2)\n",
        "G_2 = Lambda(lambda x : x[:, 2048:4096 ])(flattened_inputs_2)\n",
        "B_2 = Lambda(lambda x : x[:, 4096:     ])(flattened_inputs_2)\n",
        "R_3 = Lambda(lambda x : x[:,     :2048 ])(flattened_inputs_3)\n",
        "G_3 = Lambda(lambda x : x[:, 2048:4096 ])(flattened_inputs_3)\n",
        "B_3 = Lambda(lambda x : x[:, 4096:     ])(flattened_inputs_3)\n",
        "\n",
        "x1_1  = Lambda(lambda x : x[:,     :256 ])(R_1)\n",
        "x2_1  = Lambda(lambda x : x[:, 119 : 375 ])(R_1)\n",
        "x3_1  = Lambda(lambda x : x[:, 238 :494 ])(R_1)\n",
        "x4_1  = Lambda(lambda x : x[:, 357 : 613])(R_1)\n",
        "x5_1  = Lambda(lambda x : x[:, 476:732])(R_1)\n",
        "x6_1  = Lambda(lambda x : x[:, 595:851])(R_1)\n",
        "x7_1  = Lambda(lambda x : x[:, 714:970])(R_1)\n",
        "x8_1  = Lambda(lambda x : x[:, 833:1089])(R_1)\n",
        "x9_1  = Lambda(lambda x : x[:, 952:1208])(R_1)\n",
        "x10_1  = Lambda(lambda x : x[:, 1071:1327])(R_1)\n",
        "x11_1  = Lambda(lambda x : x[:, 1190:1446])(R_1)\n",
        "x12_1  = Lambda(lambda x : x[:, 1309:1565])(R_1)\n",
        "x13_1  = Lambda(lambda x : x[:, 1428:1684])(R_1)\n",
        "x14_1  = Lambda(lambda x : x[:, 1547:1803])(R_1)\n",
        "x15_1  = Lambda(lambda x : x[:, 1666:1922])(R_1)\n",
        "x16_1  = Lambda(lambda x : x[:, 1785:2041])(R_1)\n",
        "\n",
        "x1_1  = Tea(64)(x1_1)\n",
        "x2_1  = Tea(64)(x2_1)\n",
        "x3_1  = Tea(64)(x3_1)\n",
        "x4_1  = Tea(64)(x4_1)\n",
        "x5_1  = Tea(64)(x5_1)\n",
        "x6_1  = Tea(64)(x6_1)\n",
        "x7_1  = Tea(64)(x7_1)\n",
        "x8_1  = Tea(64)(x8_1)\n",
        "x9_1  = Tea(64)(x9_1)\n",
        "x10_1  = Tea(64)(x10_1)\n",
        "x11_1  = Tea(64)(x11_1)\n",
        "x12_1  = Tea(64)(x12_1)\n",
        "x13_1  = Tea(64)(x13_1)\n",
        "x14_1  = Tea(64)(x14_1)\n",
        "x15_1  = Tea(64)(x15_1)\n",
        "x16_1  = Tea(64)(x16_1)\n",
        "\n",
        "x1_2  = Lambda(lambda x : x[:,     :256 ])(G_1)\n",
        "x2_2  = Lambda(lambda x : x[:, 119 : 375 ])(G_1)\n",
        "x3_2  = Lambda(lambda x : x[:, 238 :494 ])(G_1)\n",
        "x4_2  = Lambda(lambda x : x[:, 357 : 613])(G_1)\n",
        "x5_2  = Lambda(lambda x : x[:, 476:732])(G_1)\n",
        "x6_2  = Lambda(lambda x : x[:, 595:851])(G_1)\n",
        "x7_2  = Lambda(lambda x : x[:, 714:970])(G_1)\n",
        "x8_2  = Lambda(lambda x : x[:, 833:1089])(G_1)\n",
        "x9_2  = Lambda(lambda x : x[:, 952:1208])(G_1)\n",
        "x10_2  = Lambda(lambda x : x[:, 1071:1327])(G_1)\n",
        "x11_2  = Lambda(lambda x : x[:, 1190:1446])(G_1)\n",
        "x12_2  = Lambda(lambda x : x[:, 1309:1565])(G_1)\n",
        "x13_2  = Lambda(lambda x : x[:, 1428:1684])(G_1)\n",
        "x14_2  = Lambda(lambda x : x[:, 1547:1803])(G_1)\n",
        "x15_2  = Lambda(lambda x : x[:, 1666:1922])(G_1)\n",
        "x16_2  = Lambda(lambda x : x[:, 1785:2041])(G_1)\n",
        "\n",
        "x1_2  = Tea(64)(x1_2)\n",
        "x2_2  = Tea(64)(x2_2)\n",
        "x3_2  = Tea(64)(x3_2)\n",
        "x4_2  = Tea(64)(x4_2)\n",
        "x5_2  = Tea(64)(x5_2)\n",
        "x6_2  = Tea(64)(x6_2)\n",
        "x7_2  = Tea(64)(x7_2)\n",
        "x8_2  = Tea(64)(x8_2)\n",
        "x9_2  = Tea(64)(x9_2)\n",
        "x10_2  = Tea(64)(x10_2)\n",
        "x11_2  = Tea(64)(x11_2)\n",
        "x12_2  = Tea(64)(x12_2)\n",
        "x13_2  = Tea(64)(x13_2)\n",
        "x14_2  = Tea(64)(x14_2)\n",
        "x15_2  = Tea(64)(x15_2)\n",
        "x16_2  = Tea(64)(x16_2)\n",
        "\n",
        "x1_3  = Lambda(lambda x : x[:,     :256 ])(B_1)\n",
        "x2_3  = Lambda(lambda x : x[:, 119 : 375 ])(B_1)\n",
        "x3_3  = Lambda(lambda x : x[:, 238 :494 ])(B_1)\n",
        "x4_3  = Lambda(lambda x : x[:, 357 : 613])(B_1)\n",
        "x5_3  = Lambda(lambda x : x[:, 476:732])(B_1)\n",
        "x6_3  = Lambda(lambda x : x[:, 595:851])(B_1)\n",
        "x7_3  = Lambda(lambda x : x[:, 714:970])(B_1)\n",
        "x8_3  = Lambda(lambda x : x[:, 833:1089])(B_1)\n",
        "x9_3  = Lambda(lambda x : x[:, 952:1208])(B_1)\n",
        "x10_3  = Lambda(lambda x : x[:, 1071:1327])(B_1)\n",
        "x11_3  = Lambda(lambda x : x[:, 1190:1446])(B_1)\n",
        "x12_3  = Lambda(lambda x : x[:, 1309:1565])(B_1)\n",
        "x13_3  = Lambda(lambda x : x[:, 1428:1684])(B_1)\n",
        "x14_3  = Lambda(lambda x : x[:, 1547:1803])(B_1)\n",
        "x15_3  = Lambda(lambda x : x[:, 1666:1922])(B_1)\n",
        "x16_3  = Lambda(lambda x : x[:, 1785:2041])(B_1)\n",
        "\n",
        "x1_3  = Tea(64)(x1_3)\n",
        "x2_3  = Tea(64)(x2_3)\n",
        "x3_3  = Tea(64)(x3_3)\n",
        "x4_3  = Tea(64)(x4_3)\n",
        "x5_3  = Tea(64)(x5_3)\n",
        "x6_3  = Tea(64)(x6_3)\n",
        "x7_3  = Tea(64)(x7_3)\n",
        "x8_3  = Tea(64)(x8_3)\n",
        "x9_3  = Tea(64)(x9_3)\n",
        "x10_3  = Tea(64)(x10_3)\n",
        "x11_3  = Tea(64)(x11_3)\n",
        "x12_3  = Tea(64)(x12_3)\n",
        "x13_3  = Tea(64)(x13_3)\n",
        "x14_3  = Tea(64)(x14_3)\n",
        "x15_3  = Tea(64)(x15_3)\n",
        "x16_3  = Tea(64)(x16_3)\n",
        "\n",
        "### 2 ###\n",
        "\n",
        "x1_4  = Lambda(lambda x : x[:,     :256 ])(R_2)\n",
        "x2_4  = Lambda(lambda x : x[:, 119 : 375 ])(R_2)\n",
        "x3_4  = Lambda(lambda x : x[:, 238 :494 ])(R_2)\n",
        "x4_4  = Lambda(lambda x : x[:, 357 : 613])(R_2)\n",
        "x5_4  = Lambda(lambda x : x[:, 476:732])(R_2)\n",
        "x6_4  = Lambda(lambda x : x[:, 595:851])(R_2)\n",
        "x7_4  = Lambda(lambda x : x[:, 714:970])(R_2)\n",
        "x8_4  = Lambda(lambda x : x[:, 833:1089])(R_2)\n",
        "x9_4  = Lambda(lambda x : x[:, 952:1208])(R_2)\n",
        "x10_4  = Lambda(lambda x : x[:, 1071:1327])(R_2)\n",
        "x11_4  = Lambda(lambda x : x[:, 1190:1446])(R_2)\n",
        "x12_4  = Lambda(lambda x : x[:, 1309:1565])(R_2)\n",
        "x13_4  = Lambda(lambda x : x[:, 1428:1684])(R_2)\n",
        "x14_4  = Lambda(lambda x : x[:, 1547:1803])(R_2)\n",
        "x15_4  = Lambda(lambda x : x[:, 1666:1922])(R_2)\n",
        "x16_4  = Lambda(lambda x : x[:, 1785:2041])(R_2)\n",
        "\n",
        "x1_4  = Tea(64)(x1_4)\n",
        "x2_4  = Tea(64)(x2_4)\n",
        "x3_4  = Tea(64)(x3_4)\n",
        "x4_4  = Tea(64)(x4_4)\n",
        "x5_4  = Tea(64)(x5_4)\n",
        "x6_4  = Tea(64)(x6_4)\n",
        "x7_4  = Tea(64)(x7_4)\n",
        "x8_4  = Tea(64)(x8_4)\n",
        "x9_4  = Tea(64)(x9_4)\n",
        "x10_4  = Tea(64)(x10_4)\n",
        "x11_4  = Tea(64)(x11_4)\n",
        "x12_4  = Tea(64)(x12_4)\n",
        "x13_4  = Tea(64)(x13_4)\n",
        "x14_4  = Tea(64)(x14_4)\n",
        "x15_4  = Tea(64)(x15_4)\n",
        "x16_4  = Tea(64)(x16_4)\n",
        "\n",
        "x1_5  = Lambda(lambda x : x[:,     :256 ])(G_2)\n",
        "x2_5  = Lambda(lambda x : x[:, 119 : 375 ])(G_2)\n",
        "x3_5  = Lambda(lambda x : x[:, 238 :494 ])(G_2)\n",
        "x4_5  = Lambda(lambda x : x[:, 357 : 613])(G_2)\n",
        "x5_5  = Lambda(lambda x : x[:, 476:732])(G_2)\n",
        "x6_5  = Lambda(lambda x : x[:, 595:851])(G_2)\n",
        "x7_5  = Lambda(lambda x : x[:, 714:970])(G_2)\n",
        "x8_5  = Lambda(lambda x : x[:, 833:1089])(G_2)\n",
        "x9_5  = Lambda(lambda x : x[:, 952:1208])(G_2)\n",
        "x10_5  = Lambda(lambda x : x[:, 1071:1327])(G_2)\n",
        "x11_5  = Lambda(lambda x : x[:, 1190:1446])(G_2)\n",
        "x12_5  = Lambda(lambda x : x[:, 1309:1565])(G_2)\n",
        "x13_5  = Lambda(lambda x : x[:, 1428:1684])(G_2)\n",
        "x14_5  = Lambda(lambda x : x[:, 1547:1803])(G_2)\n",
        "x15_5  = Lambda(lambda x : x[:, 1666:1922])(G_2)\n",
        "x16_5  = Lambda(lambda x : x[:, 1785:2041])(G_2)\n",
        "\n",
        "x1_5  = Tea(64)(x1_5)\n",
        "x2_5  = Tea(64)(x2_5)\n",
        "x3_5  = Tea(64)(x3_5)\n",
        "x4_5  = Tea(64)(x4_5)\n",
        "x5_5  = Tea(64)(x5_5)\n",
        "x6_5  = Tea(64)(x6_5)\n",
        "x7_5  = Tea(64)(x7_5)\n",
        "x8_5  = Tea(64)(x8_5)\n",
        "x9_5  = Tea(64)(x9_5)\n",
        "x10_5  = Tea(64)(x10_5)\n",
        "x11_5  = Tea(64)(x11_5)\n",
        "x12_5  = Tea(64)(x12_5)\n",
        "x13_5  = Tea(64)(x13_5)\n",
        "x14_5  = Tea(64)(x14_5)\n",
        "x15_5  = Tea(64)(x15_5)\n",
        "x16_5  = Tea(64)(x16_5)\n",
        "\n",
        "x1_6  = Lambda(lambda x : x[:,     :256 ])(B_2)\n",
        "x2_6  = Lambda(lambda x : x[:, 119 : 375 ])(B_2)\n",
        "x3_6  = Lambda(lambda x : x[:, 238 :494 ])(B_2)\n",
        "x4_6  = Lambda(lambda x : x[:, 357 : 613])(B_2)\n",
        "x5_6  = Lambda(lambda x : x[:, 476:732])(B_2)\n",
        "x6_6  = Lambda(lambda x : x[:, 595:851])(B_2)\n",
        "x7_6  = Lambda(lambda x : x[:, 714:970])(B_2)\n",
        "x8_6  = Lambda(lambda x : x[:, 833:1089])(B_2)\n",
        "x9_6  = Lambda(lambda x : x[:, 952:1208])(B_2)\n",
        "x10_6  = Lambda(lambda x : x[:, 1071:1327])(B_2)\n",
        "x11_6  = Lambda(lambda x : x[:, 1190:1446])(B_2)\n",
        "x12_6  = Lambda(lambda x : x[:, 1309:1565])(B_2)\n",
        "x13_6  = Lambda(lambda x : x[:, 1428:1684])(B_2)\n",
        "x14_6  = Lambda(lambda x : x[:, 1547:1803])(B_2)\n",
        "x15_6  = Lambda(lambda x : x[:, 1666:1922])(B_2)\n",
        "x16_6  = Lambda(lambda x : x[:, 1785:2041])(B_2)\n",
        "\n",
        "x1_6  = Tea(64)(x1_6)\n",
        "x2_6  = Tea(64)(x2_6)\n",
        "x3_6  = Tea(64)(x3_6)\n",
        "x4_6  = Tea(64)(x4_6)\n",
        "x5_6  = Tea(64)(x5_6)\n",
        "x6_6  = Tea(64)(x6_6)\n",
        "x7_6  = Tea(64)(x7_6)\n",
        "x8_6  = Tea(64)(x8_6)\n",
        "x9_6  = Tea(64)(x9_6)\n",
        "x10_6  = Tea(64)(x10_6)\n",
        "x11_6  = Tea(64)(x11_6)\n",
        "x12_6  = Tea(64)(x12_6)\n",
        "x13_6  = Tea(64)(x13_6)\n",
        "x14_6  = Tea(64)(x14_6)\n",
        "x15_6  = Tea(64)(x15_6)\n",
        "x16_6  = Tea(64)(x16_6)\n",
        "\n",
        "### 3 ###\n",
        "\n",
        "x1_7  = Lambda(lambda x : x[:,     :256 ])(R_3)\n",
        "x2_7  = Lambda(lambda x : x[:, 119 : 375 ])(R_3)\n",
        "x3_7  = Lambda(lambda x : x[:, 238 :494 ])(R_3)\n",
        "x4_7  = Lambda(lambda x : x[:, 357 : 613])(R_3)\n",
        "x5_7  = Lambda(lambda x : x[:, 476:732])(R_3)\n",
        "x6_7  = Lambda(lambda x : x[:, 595:851])(R_3)\n",
        "x7_7  = Lambda(lambda x : x[:, 714:970])(R_3)\n",
        "x8_7  = Lambda(lambda x : x[:, 833:1089])(R_3)\n",
        "x9_7  = Lambda(lambda x : x[:, 952:1208])(R_3)\n",
        "x10_7  = Lambda(lambda x : x[:, 1071:1327])(R_3)\n",
        "x11_7  = Lambda(lambda x : x[:, 1190:1446])(R_3)\n",
        "x12_7  = Lambda(lambda x : x[:, 1309:1565])(R_3)\n",
        "x13_7  = Lambda(lambda x : x[:, 1428:1684])(R_3)\n",
        "x14_7  = Lambda(lambda x : x[:, 1547:1803])(R_3)\n",
        "x15_7  = Lambda(lambda x : x[:, 1666:1922])(R_3)\n",
        "x16_7  = Lambda(lambda x : x[:, 1785:2041])(R_3)\n",
        "\n",
        "x1_7  = Tea(64)(x1_7)\n",
        "x2_7  = Tea(64)(x2_7)\n",
        "x3_7  = Tea(64)(x3_7)\n",
        "x4_7  = Tea(64)(x4_7)\n",
        "x5_7  = Tea(64)(x5_7)\n",
        "x6_7  = Tea(64)(x6_7)\n",
        "x7_7  = Tea(64)(x7_7)\n",
        "x8_7  = Tea(64)(x8_7)\n",
        "x9_7  = Tea(64)(x9_7)\n",
        "x10_7  = Tea(64)(x10_7)\n",
        "x11_7  = Tea(64)(x11_7)\n",
        "x12_7  = Tea(64)(x12_7)\n",
        "x13_7  = Tea(64)(x13_7)\n",
        "x14_7  = Tea(64)(x14_7)\n",
        "x15_7  = Tea(64)(x15_7)\n",
        "x16_7  = Tea(64)(x16_7)\n",
        "\n",
        "x1_8  = Lambda(lambda x : x[:,     :256 ])(G_3)\n",
        "x2_8  = Lambda(lambda x : x[:, 119 : 375 ])(G_3)\n",
        "x3_8  = Lambda(lambda x : x[:, 238 :494 ])(G_3)\n",
        "x4_8  = Lambda(lambda x : x[:, 357 : 613])(G_3)\n",
        "x5_8  = Lambda(lambda x : x[:, 476:732])(G_3)\n",
        "x6_8  = Lambda(lambda x : x[:, 595:851])(G_3)\n",
        "x7_8  = Lambda(lambda x : x[:, 714:970])(G_3)\n",
        "x8_8  = Lambda(lambda x : x[:, 833:1089])(G_3)\n",
        "x9_8  = Lambda(lambda x : x[:, 952:1208])(G_3)\n",
        "x10_8  = Lambda(lambda x : x[:, 1071:1327])(G_3)\n",
        "x11_8  = Lambda(lambda x : x[:, 1190:1446])(G_3)\n",
        "x12_8  = Lambda(lambda x : x[:, 1309:1565])(G_3)\n",
        "x13_8  = Lambda(lambda x : x[:, 1428:1684])(G_3)\n",
        "x14_8  = Lambda(lambda x : x[:, 1547:1803])(G_3)\n",
        "x15_8  = Lambda(lambda x : x[:, 1666:1922])(G_3)\n",
        "x16_8  = Lambda(lambda x : x[:, 1785:2041])(G_3)\n",
        "\n",
        "x1_8  = Tea(64)(x1_8)\n",
        "x2_8  = Tea(64)(x2_8)\n",
        "x3_8  = Tea(64)(x3_8)\n",
        "x4_8  = Tea(64)(x4_8)\n",
        "x5_8  = Tea(64)(x5_8)\n",
        "x6_8  = Tea(64)(x6_8)\n",
        "x7_8  = Tea(64)(x7_8)\n",
        "x8_8  = Tea(64)(x8_8)\n",
        "x9_8  = Tea(64)(x9_8)\n",
        "x10_8  = Tea(64)(x10_8)\n",
        "x11_8  = Tea(64)(x11_8)\n",
        "x12_8  = Tea(64)(x12_8)\n",
        "x13_8  = Tea(64)(x13_8)\n",
        "x14_8  = Tea(64)(x14_8)\n",
        "x15_8  = Tea(64)(x15_8)\n",
        "x16_8  = Tea(64)(x16_8)\n",
        "\n",
        "x1_9  = Lambda(lambda x : x[:,     :256 ])(B_3)\n",
        "x2_9  = Lambda(lambda x : x[:, 119 : 375 ])(B_3)\n",
        "x3_9  = Lambda(lambda x : x[:, 238 :494 ])(B_3)\n",
        "x4_9  = Lambda(lambda x : x[:, 357 : 613])(B_3)\n",
        "x5_9  = Lambda(lambda x : x[:, 476:732])(B_3)\n",
        "x6_9  = Lambda(lambda x : x[:, 595:851])(B_3)\n",
        "x7_9  = Lambda(lambda x : x[:, 714:970])(B_3)\n",
        "x8_9  = Lambda(lambda x : x[:, 833:1089])(B_3)\n",
        "x9_9  = Lambda(lambda x : x[:, 952:1208])(B_3)\n",
        "x10_9  = Lambda(lambda x : x[:, 1071:1327])(B_3)\n",
        "x11_9  = Lambda(lambda x : x[:, 1190:1446])(B_3)\n",
        "x12_9  = Lambda(lambda x : x[:, 1309:1565])(B_3)\n",
        "x13_9  = Lambda(lambda x : x[:, 1428:1684])(B_3)\n",
        "x14_9  = Lambda(lambda x : x[:, 1547:1803])(B_3)\n",
        "x15_9  = Lambda(lambda x : x[:, 1666:1922])(B_3)\n",
        "x16_9  = Lambda(lambda x : x[:, 1785:2041])(B_3)\n",
        "\n",
        "x1_9  = Tea(64)(x1_9)\n",
        "x2_9  = Tea(64)(x2_9)\n",
        "x3_9  = Tea(64)(x3_9)\n",
        "x4_9  = Tea(64)(x4_9)\n",
        "x5_9  = Tea(64)(x5_9)\n",
        "x6_9  = Tea(64)(x6_9)\n",
        "x7_9  = Tea(64)(x7_9)\n",
        "x8_9  = Tea(64)(x8_9)\n",
        "x9_9  = Tea(64)(x9_9)\n",
        "x10_9  = Tea(64)(x10_9)\n",
        "x11_9  = Tea(64)(x11_9)\n",
        "x12_9  = Tea(64)(x12_9)\n",
        "x13_9  = Tea(64)(x13_9)\n",
        "x14_9  = Tea(64)(x14_9)\n",
        "x15_9  = Tea(64)(x15_9)\n",
        "x16_9  = Tea(64)(x16_9)\n",
        "\n",
        "x1_1_1 = Average()([x1_1,x1_2,x1_3,x1_4,x1_5,x1_6,x1_7,x1_8,x1_9])\n",
        "x2_1_1 = Average()([x2_1,x2_2,x2_3,x2_4,x2_5,x2_6,x2_7,x2_8,x2_9])\n",
        "x3_1_1 = Average()([x3_1,x3_2,x3_3,x3_4,x3_5,x3_6,x3_7,x3_8,x3_9])\n",
        "x4_1_1 = Average()([x4_1,x4_2,x4_3,x4_4,x4_5,x4_6,x4_7,x4_8,x4_9])\n",
        "x5_1_1 = Average()([x5_1,x5_2,x5_3,x5_4,x5_5,x5_6,x5_7,x5_8,x5_9])\n",
        "x6_1_1 = Average()([x6_1,x6_2,x6_3,x6_4,x6_5,x6_6,x6_7,x6_8,x6_9])\n",
        "x7_1_1 = Average()([x7_1,x7_2,x7_3,x7_4,x7_5,x7_6,x7_7,x7_8,x7_9])\n",
        "x8_1_1 = Average()([x8_1,x8_2,x8_3,x8_4,x8_5,x8_6,x8_7,x8_8,x8_9])\n",
        "x9_1_1 = Average()([x9_1,x9_2,x9_3,x9_4,x9_5,x9_6,x9_7,x9_8,x9_9])\n",
        "x10_1_1 = Average()([x10_1,x10_2,x10_3,x10_4,x10_5,x10_6,x10_7,x10_8,x10_9])\n",
        "x11_1_1 = Average()([x11_1,x11_2,x11_3,x11_4,x11_5,x11_6,x11_7,x11_8,x11_9])\n",
        "x12_1_1 = Average()([x12_1,x12_2,x12_3,x12_4,x12_5,x12_6,x12_7,x12_8,x12_9])\n",
        "x13_1_1 = Average()([x13_1,x13_2,x13_3,x13_4,x13_5,x13_6,x13_7,x13_8,x13_9])\n",
        "x14_1_1 = Average()([x14_1,x14_2,x14_3,x14_4,x14_5,x14_6,x14_7,x14_8,x14_9])\n",
        "x15_1_1 = Average()([x15_1,x15_2,x15_3,x15_4,x15_5,x15_6,x15_7,x15_8,x15_9])\n",
        "x16_1_1 = Average()([x16_1,x16_2,x16_3,x16_4,x16_5,x16_6,x16_7,x16_8,x16_9])\n",
        "\n",
        "x1 = concatenate(([x1_1_1,x2_1_1,x3_1_1,x4_1_1]),axis=1)\n",
        "x2 = concatenate(([x5_1_1,x6_1_1,x7_1_1,x8_1_1]),axis=1)\n",
        "x3 = concatenate(([x9_1_1,x10_1_1,x11_1_1,x12_1_1]),axis=1)\n",
        "x4 = concatenate(([x13_1_1,x14_1_1,x15_1_1,x16_1_1]),axis=1)\n",
        "\n",
        "x1_1 = Tea(64)(x1)\n",
        "x2_1 = Tea(64)(x2)\n",
        "x3_1 = Tea(64)(x3)\n",
        "x4_1 = Tea(64)(x4)\n",
        "\n",
        "x_out = concatenate(([x1_1,x2_1,x3_1,x4_1]),axis=1)\n",
        "x_out = Tea(252)(x_out)\n",
        "\n",
        "x_out = AdditivePooling(9)(x_out)\n",
        "\n",
        "predictions = Activation('softmax')(x_out)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.0005),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-{}'.format(sub)\n",
        "# ckpt_name = '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-best'\n",
        "\n",
        "import keras \n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath + '-epoch-{epoch}',\n",
        "    # filepath = ckpt_name,\n",
        "    save_weights_only=True,\n",
        "    # save_best_only = True)\n",
        "    )\n",
        "\n",
        "# model.load_weights(\"/content/drive/MyDrive/RANC/ckpt_supine/9_class_deep-{}\".format(sub)) \n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          callbacks=[model_checkpoint_callback],\n",
        "          validation_split = 0.2)\n",
        "\n",
        "import os\n",
        "scores = []\n",
        "soure = \"/content/drive/MyDrive/RANC/ckpt_2\"\n",
        "# ckpts = [os.path.join(soure,e) for e in os.listdir(soure) if sub in e]\n",
        "ckpts = [\"/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-\"+ str(i) for i in range(1,51)]\n",
        "for ckpt in ckpts:\n",
        "    print(\"======================================\")\n",
        "    print(ckpt)\n",
        "    print(\"======================================\")\n",
        "    model.load_weights(ckpt)      \n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    scores.append(score[1])\n",
        "\n",
        "# model.load_weights(\"/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-best\")     \n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])\n",
        "\n",
        "print(\"Max accuracy:\",max(scores))\n",
        "print(\"Best epoch:\",ckpts[scores.index(max(scores))])\n",
        "\n"
      ],
      "metadata": {
        "id": "HK9skyPRUmpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebacc71-2070-4f98-e9b8-4be4a3e84249"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 6924 samples, validate on 1732 samples\n",
            "Epoch 1/50\n",
            "6924/6924 [==============================] - ETA: 0s - loss: 0.4531 - acc: 0.8651"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6924/6924 [==============================] - 14s 2ms/sample - loss: 0.4531 - acc: 0.8651 - val_loss: 1.7401 - val_acc: 0.5462\n",
            "Epoch 2/50\n",
            "6924/6924 [==============================] - 5s 733us/sample - loss: 0.0160 - acc: 0.9983 - val_loss: 1.7512 - val_acc: 0.5947\n",
            "Epoch 3/50\n",
            "6924/6924 [==============================] - 5s 730us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.6975 - val_acc: 0.6403\n",
            "Epoch 4/50\n",
            "6924/6924 [==============================] - 5s 792us/sample - loss: 0.0035 - acc: 0.9996 - val_loss: 1.7244 - val_acc: 0.6103\n",
            "Epoch 5/50\n",
            "6924/6924 [==============================] - 5s 735us/sample - loss: 0.0041 - acc: 0.9999 - val_loss: 1.4683 - val_acc: 0.6570\n",
            "Epoch 6/50\n",
            "6924/6924 [==============================] - 6s 795us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 1.7222 - val_acc: 0.6495\n",
            "Epoch 7/50\n",
            "6924/6924 [==============================] - 5s 740us/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 1.8274 - val_acc: 0.6085\n",
            "Epoch 8/50\n",
            "6924/6924 [==============================] - 5s 789us/sample - loss: 0.0368 - acc: 0.9909 - val_loss: 2.0361 - val_acc: 0.5658\n",
            "Epoch 9/50\n",
            "6924/6924 [==============================] - 5s 763us/sample - loss: 0.0014 - acc: 0.9999 - val_loss: 2.0113 - val_acc: 0.6259\n",
            "Epoch 10/50\n",
            "6924/6924 [==============================] - 8s 1ms/sample - loss: 4.0253e-04 - acc: 1.0000 - val_loss: 2.1275 - val_acc: 0.6184\n",
            "Epoch 11/50\n",
            "6924/6924 [==============================] - 5s 778us/sample - loss: 2.5011e-04 - acc: 1.0000 - val_loss: 2.2154 - val_acc: 0.6189\n",
            "Epoch 12/50\n",
            "6924/6924 [==============================] - 5s 754us/sample - loss: 1.8135e-04 - acc: 1.0000 - val_loss: 2.1537 - val_acc: 0.6224\n",
            "Epoch 13/50\n",
            "6924/6924 [==============================] - 5s 736us/sample - loss: 1.5692e-04 - acc: 1.0000 - val_loss: 2.2394 - val_acc: 0.6247\n",
            "Epoch 14/50\n",
            "6924/6924 [==============================] - 5s 771us/sample - loss: 1.5879e-04 - acc: 1.0000 - val_loss: 2.1597 - val_acc: 0.6201\n",
            "Epoch 15/50\n",
            "6924/6924 [==============================] - 5s 744us/sample - loss: 1.3208e-04 - acc: 1.0000 - val_loss: 2.1887 - val_acc: 0.6143\n",
            "Epoch 16/50\n",
            "6924/6924 [==============================] - 6s 803us/sample - loss: 1.0386e-04 - acc: 1.0000 - val_loss: 2.1455 - val_acc: 0.6334\n",
            "Epoch 17/50\n",
            "6924/6924 [==============================] - 5s 755us/sample - loss: 8.7104e-05 - acc: 1.0000 - val_loss: 2.2832 - val_acc: 0.6161\n",
            "Epoch 18/50\n",
            "6924/6924 [==============================] - 6s 804us/sample - loss: 8.2109e-05 - acc: 1.0000 - val_loss: 2.3550 - val_acc: 0.6189\n",
            "Epoch 19/50\n",
            "6924/6924 [==============================] - 5s 750us/sample - loss: 7.4284e-05 - acc: 1.0000 - val_loss: 2.4804 - val_acc: 0.6132\n",
            "Epoch 20/50\n",
            "6924/6924 [==============================] - 5s 771us/sample - loss: 6.6021e-05 - acc: 1.0000 - val_loss: 2.3895 - val_acc: 0.6230\n",
            "Epoch 21/50\n",
            "6924/6924 [==============================] - 5s 765us/sample - loss: 5.9867e-05 - acc: 1.0000 - val_loss: 2.4186 - val_acc: 0.6126\n",
            "Epoch 22/50\n",
            "6924/6924 [==============================] - 5s 770us/sample - loss: 8.2497e-05 - acc: 1.0000 - val_loss: 2.4395 - val_acc: 0.6114\n",
            "Epoch 23/50\n",
            "6924/6924 [==============================] - 5s 747us/sample - loss: 5.4850e-05 - acc: 1.0000 - val_loss: 2.5230 - val_acc: 0.6033\n",
            "Epoch 24/50\n",
            "6924/6924 [==============================] - 5s 741us/sample - loss: 4.8885e-05 - acc: 1.0000 - val_loss: 2.5958 - val_acc: 0.6022\n",
            "Epoch 25/50\n",
            "6924/6924 [==============================] - 5s 758us/sample - loss: 4.2972e-05 - acc: 1.0000 - val_loss: 2.6134 - val_acc: 0.6109\n",
            "Epoch 26/50\n",
            "6924/6924 [==============================] - 5s 748us/sample - loss: 4.4032e-05 - acc: 1.0000 - val_loss: 2.6868 - val_acc: 0.6005\n",
            "Epoch 27/50\n",
            "6924/6924 [==============================] - 5s 784us/sample - loss: 3.7663e-05 - acc: 1.0000 - val_loss: 2.7307 - val_acc: 0.6068\n",
            "Epoch 28/50\n",
            "6924/6924 [==============================] - 5s 747us/sample - loss: 3.4560e-05 - acc: 1.0000 - val_loss: 2.7091 - val_acc: 0.6062\n",
            "Epoch 29/50\n",
            "6924/6924 [==============================] - 5s 763us/sample - loss: 3.3556e-05 - acc: 1.0000 - val_loss: 2.5987 - val_acc: 0.6132\n",
            "Epoch 30/50\n",
            "6924/6924 [==============================] - 5s 754us/sample - loss: 3.0768e-05 - acc: 1.0000 - val_loss: 2.6018 - val_acc: 0.6207\n",
            "Epoch 31/50\n",
            "6924/6924 [==============================] - 5s 729us/sample - loss: 2.9163e-05 - acc: 1.0000 - val_loss: 2.5503 - val_acc: 0.6218\n",
            "Epoch 32/50\n",
            "6924/6924 [==============================] - 5s 780us/sample - loss: 2.8387e-05 - acc: 1.0000 - val_loss: 2.5499 - val_acc: 0.6236\n",
            "Epoch 33/50\n",
            "6924/6924 [==============================] - 5s 753us/sample - loss: 2.7097e-05 - acc: 1.0000 - val_loss: 2.5890 - val_acc: 0.6224\n",
            "Epoch 34/50\n",
            "6924/6924 [==============================] - 5s 791us/sample - loss: 2.5977e-05 - acc: 1.0000 - val_loss: 2.4377 - val_acc: 0.6264\n",
            "Epoch 35/50\n",
            "6924/6924 [==============================] - 6s 797us/sample - loss: 2.5031e-05 - acc: 1.0000 - val_loss: 2.5006 - val_acc: 0.6259\n",
            "Epoch 36/50\n",
            "6924/6924 [==============================] - 5s 768us/sample - loss: 2.2470e-05 - acc: 1.0000 - val_loss: 2.4379 - val_acc: 0.6345\n",
            "Epoch 37/50\n",
            "6924/6924 [==============================] - 5s 769us/sample - loss: 2.2626e-05 - acc: 1.0000 - val_loss: 2.6101 - val_acc: 0.6097\n",
            "Epoch 38/50\n",
            "6924/6924 [==============================] - 5s 762us/sample - loss: 2.6206e-05 - acc: 1.0000 - val_loss: 2.6314 - val_acc: 0.6230\n",
            "Epoch 39/50\n",
            "6924/6924 [==============================] - 6s 855us/sample - loss: 2.1270e-05 - acc: 1.0000 - val_loss: 2.5549 - val_acc: 0.6143\n",
            "Epoch 40/50\n",
            "6924/6924 [==============================] - 5s 777us/sample - loss: 1.8472e-05 - acc: 1.0000 - val_loss: 2.5780 - val_acc: 0.6224\n",
            "Epoch 41/50\n",
            "6924/6924 [==============================] - 5s 759us/sample - loss: 1.7626e-05 - acc: 1.0000 - val_loss: 2.5331 - val_acc: 0.6230\n",
            "Epoch 42/50\n",
            "6924/6924 [==============================] - 5s 765us/sample - loss: 1.8068e-05 - acc: 1.0000 - val_loss: 2.5328 - val_acc: 0.6230\n",
            "Epoch 43/50\n",
            "6924/6924 [==============================] - 5s 771us/sample - loss: 1.8643e-05 - acc: 1.0000 - val_loss: 2.4686 - val_acc: 0.6339\n",
            "Epoch 44/50\n",
            "6924/6924 [==============================] - 5s 757us/sample - loss: 1.9324e-05 - acc: 1.0000 - val_loss: 2.4909 - val_acc: 0.6339\n",
            "Epoch 45/50\n",
            "6924/6924 [==============================] - 5s 735us/sample - loss: 1.8112e-05 - acc: 1.0000 - val_loss: 2.3416 - val_acc: 0.6276\n",
            "Epoch 46/50\n",
            "6924/6924 [==============================] - 5s 790us/sample - loss: 1.5312e-05 - acc: 1.0000 - val_loss: 2.3207 - val_acc: 0.6334\n",
            "Epoch 47/50\n",
            "6924/6924 [==============================] - 5s 744us/sample - loss: 1.4515e-05 - acc: 1.0000 - val_loss: 2.3325 - val_acc: 0.6542\n",
            "Epoch 48/50\n",
            "6924/6924 [==============================] - 5s 764us/sample - loss: 1.4737e-05 - acc: 1.0000 - val_loss: 2.2487 - val_acc: 0.6559\n",
            "Epoch 49/50\n",
            "6924/6924 [==============================] - 5s 756us/sample - loss: 1.4360e-05 - acc: 1.0000 - val_loss: 2.3854 - val_acc: 0.6472\n",
            "Epoch 50/50\n",
            "6924/6924 [==============================] - 5s 774us/sample - loss: 1.2555e-05 - acc: 1.0000 - val_loss: 2.4099 - val_acc: 0.6490\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-1\n",
            "======================================\n",
            "Test loss: 0.9390249404833934\n",
            "Test accuracy: 0.7450271\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-2\n",
            "======================================\n",
            "Test loss: 0.9163321785318916\n",
            "Test accuracy: 0.8028933\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-3\n",
            "======================================\n",
            "Test loss: 1.0954683109996655\n",
            "Test accuracy: 0.79566\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-4\n",
            "======================================\n",
            "Test loss: 1.124621360261283\n",
            "Test accuracy: 0.73779386\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-5\n",
            "======================================\n",
            "Test loss: 1.0082664474858405\n",
            "Test accuracy: 0.75406873\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-6\n",
            "======================================\n",
            "Test loss: 0.9580895464840408\n",
            "Test accuracy: 0.77938515\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-7\n",
            "======================================\n",
            "Test loss: 1.0249379748591367\n",
            "Test accuracy: 0.755877\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-8\n",
            "======================================\n",
            "Test loss: 0.39199777022610416\n",
            "Test accuracy: 0.8661845\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-9\n",
            "======================================\n",
            "Test loss: 0.7402499026069872\n",
            "Test accuracy: 0.7414105\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-10\n",
            "======================================\n",
            "Test loss: 0.5683223631462019\n",
            "Test accuracy: 0.8101266\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-11\n",
            "======================================\n",
            "Test loss: 0.6209576772711161\n",
            "Test accuracy: 0.7811935\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-12\n",
            "======================================\n",
            "Test loss: 0.7251354373492988\n",
            "Test accuracy: 0.7866185\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-13\n",
            "======================================\n",
            "Test loss: 0.7365500065152808\n",
            "Test accuracy: 0.77396023\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-14\n",
            "======================================\n",
            "Test loss: 0.669210451063119\n",
            "Test accuracy: 0.8047016\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-15\n",
            "======================================\n",
            "Test loss: 0.688584360320569\n",
            "Test accuracy: 0.78842676\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-16\n",
            "======================================\n",
            "Test loss: 0.7953747048280176\n",
            "Test accuracy: 0.7811935\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-17\n",
            "======================================\n",
            "Test loss: 0.7235995304247004\n",
            "Test accuracy: 0.79566\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-18\n",
            "======================================\n",
            "Test loss: 0.6628907017197602\n",
            "Test accuracy: 0.83725137\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-19\n",
            "======================================\n",
            "Test loss: 0.7814040954256763\n",
            "Test accuracy: 0.7902351\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-20\n",
            "======================================\n",
            "Test loss: 0.7389003246522443\n",
            "Test accuracy: 0.7902351\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-21\n",
            "======================================\n",
            "Test loss: 0.6985830331143753\n",
            "Test accuracy: 0.7902351\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-22\n",
            "======================================\n",
            "Test loss: 0.702483987033192\n",
            "Test accuracy: 0.7848101\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-23\n",
            "======================================\n",
            "Test loss: 0.6602175711960638\n",
            "Test accuracy: 0.7902351\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-24\n",
            "======================================\n",
            "Test loss: 0.7899995576539776\n",
            "Test accuracy: 0.80831826\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-25\n",
            "======================================\n",
            "Test loss: 0.7310381166571263\n",
            "Test accuracy: 0.8028933\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-26\n",
            "======================================\n",
            "Test loss: 0.6811704608804595\n",
            "Test accuracy: 0.8101266\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-27\n",
            "======================================\n",
            "Test loss: 0.8027501194367344\n",
            "Test accuracy: 0.77396023\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-28\n",
            "======================================\n",
            "Test loss: 0.6697505399027744\n",
            "Test accuracy: 0.80651\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-29\n",
            "======================================\n",
            "Test loss: 0.7827206148263269\n",
            "Test accuracy: 0.7902351\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-30\n",
            "======================================\n",
            "Test loss: 0.8104003241865022\n",
            "Test accuracy: 0.7902351\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-31\n",
            "======================================\n",
            "Test loss: 0.7185712069303309\n",
            "Test accuracy: 0.8028933\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-32\n",
            "======================================\n",
            "Test loss: 0.6501339732258367\n",
            "Test accuracy: 0.79566\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-33\n",
            "======================================\n",
            "Test loss: 0.6757824194700092\n",
            "Test accuracy: 0.81916815\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-34\n",
            "======================================\n",
            "Test loss: 0.8952024652888733\n",
            "Test accuracy: 0.77757686\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-35\n",
            "======================================\n",
            "Test loss: 0.8662658596350719\n",
            "Test accuracy: 0.77757686\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-36\n",
            "======================================\n",
            "Test loss: 1.0420636910495515\n",
            "Test accuracy: 0.7703436\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-37\n",
            "======================================\n",
            "Test loss: 1.0224757931712227\n",
            "Test accuracy: 0.77396023\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-38\n",
            "======================================\n",
            "Test loss: 1.1297641288193119\n",
            "Test accuracy: 0.7757685\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-39\n",
            "======================================\n",
            "Test loss: 0.9438913302705749\n",
            "Test accuracy: 0.7848101\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-40\n",
            "======================================\n",
            "Test loss: 0.9044481339354142\n",
            "Test accuracy: 0.79566\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-41\n",
            "======================================\n",
            "Test loss: 1.0075255278203212\n",
            "Test accuracy: 0.801085\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-42\n",
            "======================================\n",
            "Test loss: 0.8324240719083575\n",
            "Test accuracy: 0.8047016\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-43\n",
            "======================================\n",
            "Test loss: 0.8670555186309729\n",
            "Test accuracy: 0.7866185\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-44\n",
            "======================================\n",
            "Test loss: 1.117695126063603\n",
            "Test accuracy: 0.7848101\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-45\n",
            "======================================\n",
            "Test loss: 1.0538504171538021\n",
            "Test accuracy: 0.761302\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-46\n",
            "======================================\n",
            "Test loss: 0.7400146326989906\n",
            "Test accuracy: 0.79927665\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-47\n",
            "======================================\n",
            "Test loss: 0.6788996321069806\n",
            "Test accuracy: 0.82820976\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-48\n",
            "======================================\n",
            "Test loss: 0.8685380972013051\n",
            "Test accuracy: 0.7920434\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-49\n",
            "======================================\n",
            "Test loss: 1.0565846868461017\n",
            "Test accuracy: 0.7522604\n",
            "======================================\n",
            "/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-50\n",
            "======================================\n",
            "Test loss: 1.0540134865924493\n",
            "Test accuracy: 0.76853526\n",
            "Max accuracy: 0.8661845\n",
            "Best epoch: /content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soure = \"/content/drive/MyDrive/RANC/ckpt_2\"\n",
        "ckpts = [os.path.join(soure,e) for e in os.listdir(soure) if sub in e]\n",
        "print(ckpts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMrKky8fo7up",
        "outputId": "46c12875-d13a-4a04-cbff-2fd07c58c479"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-1.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-1.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-2.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-2.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-3.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-3.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-4.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-4.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-5.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-5.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-6.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-6.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-7.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-7.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-8.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-8.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-9.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-9.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-10.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-10.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-11.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-11.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-12.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-12.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-13.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-13.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-14.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-14.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-15.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-15.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-16.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-16.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-17.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-17.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-18.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-18.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-19.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-19.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-20.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-20.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-21.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-21.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-22.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-22.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-23.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-23.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-24.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-24.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-25.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-25.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-26.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-26.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-27.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-27.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-28.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-28.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-29.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-29.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-30.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-30.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-31.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-31.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-32.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-32.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-33.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-33.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-34.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-34.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-35.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-35.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-36.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-36.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-37.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-37.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-38.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-38.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-39.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-39.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-40.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-40.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-41.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-41.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-42.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-42.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-43.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-43.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-44.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-44.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-45.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-45.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-46.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-46.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-47.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-47.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-48.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-48.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-49.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-49.index', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-50.data-00000-of-00001', '/content/drive/MyDrive/RANC/ckpt_2/9_class_deep-S2-epoch-50.index']\n"
          ]
        }
      ]
    }
  ]
}